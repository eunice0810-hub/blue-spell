import streamlit as st
from spellchecker import SpellChecker
import nltk
from nltk.tokenize import word_tokenize
from nltk.tokenize.treebank import TreebankWordDetokenizer
import pandas as pd

# ----------------------------
# NLTK setup
# ----------------------------
def ensure_nltk():
    """Ensure required NLTK resources exist (download once if missing)."""
    try:
        nltk.data.find("tokenizers/punkt")
    except LookupError:
        nltk.download("punkt")


# ----------------------------
# Helpers
# ----------------------------
def tokenize_text(text: str):
    return word_tokenize(text)


def is_candidate_word(tok: str, min_len: int, ignore_all_caps: bool, ignore_title: bool) -> bool:
    if not isinstance(tok, str):
        return False
    if not tok.isalpha():
        return False
    if len(tok) < min_len:
        return False
    if ignore_all_caps and tok.isupper():
        return False
    if ignore_title and tok.istitle():
        return False
    return True


def run_spellcheck_on_text(
    text: str,
    filename: str,
    spell_checker: SpellChecker,
    min_len: int,
    ignore_all_caps: bool,
    ignore_title: bool,
    custom_ignore: set | None = None,
):
    detok = TreebankWordDetokenizer()
    tokens = tokenize_text(text)

    candidate_indices = []
    candidate_words = []

    for i, tok in enumerate(tokens):
        if is_candidate_word(tok, min_len, ignore_all_caps, ignore_title):
            lw = tok.lower()
            if custom_ignore and lw in custom_ignore:
                continue
            candidate_indices.append(i)
            candidate_words.append(lw)

    misspelled = spell_checker.unknown(candidate_words)

    corrected_count = 0
    for i in candidate_indices:
        orig = tokens[i]
        lw = orig.lower()
        if lw not in misspelled:
            continue

        suggestion = spell_checker.correction(lw)
        if not suggestion or suggestion == lw:
            continue

        # ì›ëž˜ ëŒ€ì†Œë¬¸ìž í˜•íƒœ ìµœëŒ€í•œ ìœ ì§€
        if orig.istitle():
            suggestion = suggestion.capitalize()
        elif orig.isupper():
            suggestion = suggestion.upper()

        tokens[i] = suggestion
        corrected_count += 1

    tokens = [t if isinstance(t, str) else "" for t in tokens]
    corrected_text = detok.detokenize(tokens)

    stats = {
        "filename": filename,
        "total_tokens": len(tokens),
        "candidate_count": len(candidate_words),
        "corrected_count": corrected_count,
    }
    return corrected_text, stats


# ----------------------------
# Streamlit UI
# ----------------------------
def main():
    st.set_page_config(page_title="Blue Spell Yonsei (Streamlit)", layout="wide")

    st.title("ðŸŸ¦ Blue Spell (Yonsei Edition) â€“ Streamlit ë²„ì „")
    st.write(
        "ì—¬ëŸ¬ ê°œì˜ `.txt` íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´, "
        "ì² ìž ì˜¤ë¥˜ë¥¼ êµì •í•˜ê³  ìš”ì•½ í†µê³„ë¥¼ ë³´ì—¬ì£¼ëŠ” ì›¹ ì•±ìž…ë‹ˆë‹¤."
    )

    ensure_nltk()
    spell = SpellChecker(language="en")

    # ---- Sidebar: ì˜µì…˜ ----
    with st.sidebar:
        st.header("ì˜µì…˜")
        min_len = st.number_input("ìµœì†Œ ë‹¨ì–´ ê¸¸ì´", min_value=1, max_value=20, value=3)
        ignore_all_caps = st.checkbox("ëª¨ë‘ ëŒ€ë¬¸ìž ë‹¨ì–´ ë¬´ì‹œ (ABC)", value=True)
        ignore_title = st.checkbox("ì²« ê¸€ìžë§Œ ëŒ€ë¬¸ìž(Title Case) ë¬´ì‹œ (e.g., Yonsei)", value=True)

        st.markdown("---")
        custom_ignore_file = st.file_uploader(
            "ì»¤ìŠ¤í…€ ignore ë¦¬ìŠ¤íŠ¸ (.txt, í•œ ì¤„ë‹¹ í•œ ë‹¨ì–´)", type=["txt"], key="ignore_list"
        )

    uploaded_files = st.file_uploader(
        "ì² ìž ê²€ì‚¬í•  `.txt` íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)",
        type=["txt"],
        accept_multiple_files=True,
    )

    run_button = st.button("ì² ìž ê²€ì‚¬ ì‹¤í–‰")

    if run_button:
        if not uploaded_files:
            st.warning("ë¨¼ì € `.txt` íŒŒì¼ì„ í•˜ë‚˜ ì´ìƒ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            return

        # ì»¤ìŠ¤í…€ ignore ë¦¬ìŠ¤íŠ¸ ì½ê¸°
        custom_ignore: set[str] = set()
        if custom_ignore_file is not None:
            try:
                content = custom_ignore_file.read().decode("utf-8", errors="ignore")
                custom_ignore = {
                    line.strip().lower()
                    for line in content.splitlines()
                    if line.strip()
                }
                st.sidebar.success(f"Ignore ë‹¨ì–´ {len(custom_ignore)}ê°œ ë¡œë“œë¨")
            except Exception as e:
                st.sidebar.error(f"Ignore ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        summary_rows = []

        for file in uploaded_files:
            try:
                raw = file.read().decode("utf-8", errors="ignore")
            except Exception:
                raw = file.read().decode("cp949", errors="ignore")

            corrected_text, stats = run_spellcheck_on_text(
                raw,
                filename=file.name,
                spell_checker=spell,
                min_len=min_len,
                ignore_all_caps=ignore_all_caps,
                ignore_title=ignore_title,
                custom_ignore=custom_ignore,
            )

            st.subheader(f"íŒŒì¼: {file.name}")
            col1, col2, col3 = st.columns(3)
            col1.metric("ì „ì²´ í† í° ìˆ˜", stats["total_tokens"])
            col2.metric("ì² ìž í›„ë³´ ë‹¨ì–´ ìˆ˜", stats["candidate_count"])
            col3.metric("êµì •ëœ ë‹¨ì–´ ìˆ˜", stats["corrected_count"])

            st.text_area(
                "êµì •ëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°",
                corrected_text[:3000],
                height=200,
            )

            st.download_button(
                label="êµì •ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=corrected_text.encode("utf-8"),
                file_name=f"{file.name.rsplit('.', 1)[0]}_corrected.txt",
                mime="text/plain",
            )

            summary_rows.append(stats)

        if summary_rows:
            st.markdown("### ì „ì²´ íŒŒì¼ ìš”ì•½")
            df = pd.DataFrame(summary_rows)
            st.dataframe(df, use_container_width=True)

            csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ìš”ì•½ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_bytes,
                file_name="spelling_summary.csv",
                mime="text/csv",
            )


if __name__ == "__main__":
    main()
