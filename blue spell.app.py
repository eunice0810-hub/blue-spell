import streamlit as st
from spellchecker import SpellChecker
import nltk
from nltk.tokenize import word_tokenize
from nltk.tokenize.treebank import TreebankWordDetokenizer
import pandas as pd


# ----------------------------
# NLTK setup
# ----------------------------
def ensure_nltk():
    """Ensure required NLTK resources exist (download once if missing)."""
    try:
        nltk.data.find("tokenizers/punkt")
    except LookupError:
        nltk.download("punkt")


# ----------------------------
# Helpers
# ----------------------------
def tokenize_text(text):
    return word_tokenize(text)


def is_candidate_word(tok, min_len, ignore_all_caps, ignore_title):
    if not isinstance(tok, str):
        return False
    if not tok.isalpha():
        return False
    if len(tok) < min_len:
        return False
    if ignore_all_caps and tok.isupper():
        return False
    if ignore_title and tok.istitle():
        return False
    return True


def run_spellcheck_on_text(
    text,
    filename,
    spell_checker,
    min_len,
    ignore_all_caps,
    ignore_title,
    custom_ignore=None,
):
    detok = TreebankWordDetokenizer()
    tokens = tokenize_text(text)

    candidate_indices = []
    candidate_words = []

    for i, tok in enumerate(tokens):
        if is_candidate_word(tok, min_len, ignore_all_caps, ignore_title):
            lw = tok.lower()
            if custom_ignore and lw in custom_ignore:
                continue
            candidate_indices.append(i)
            candidate_words.append(lw)

    misspelled = spell_checker.unknown(candidate_words)

    corrected_indices = []
    corrected_count = 0

    for i in candidate_indices:
        orig = tokens[i]
        lw = orig.lower()
        if lw not in misspelled:
            continue

        suggestion = spell_checker.correction(lw)
        if not suggestion or suggestion == lw:
            continue

        # ì›ë˜ ëŒ€ì†Œë¬¸ì í˜•íƒœ ìµœëŒ€í•œ ìœ ì§€
        if orig.istitle():
            suggestion = suggestion.capitalize()
        elif orig.isupper():
            suggestion = suggestion.upper()

        tokens[i] = suggestion
        corrected_indices.append(i)
        corrected_count += 1

    # detokenizeìš© ìˆœìˆ˜ í† í°
    safe_tokens = [t if isinstance(t, str) else "" for t in tokens]
    corrected_text = detok.detokenize(safe_tokens)

    # í•˜ì´ë¼ì´íŠ¸ìš© í† í° (HTML span ê°ì‹¸ê¸°)
    display_tokens = []
    corrected_set = set(corrected_indices)
    for idx, tok in enumerate(safe_tokens):
        if idx in corrected_set and tok.strip():
            display_tokens.append(f'<span class="corrected-word">{tok}</span>')
        else:
            display_tokens.append(tok)
    highlighted_html = detok.detokenize(display_tokens)

    stats = {
        "filename": filename,
        "total_tokens": len(safe_tokens),
        "candidate_count": len(candidate_words),
        "corrected_count": corrected_count,
    }
    return corrected_text, highlighted_html, stats


# ----------------------------
# Streamlit UI
# ----------------------------
def main():
    st.set_page_config(
        page_title="Blue Spell (Yonsei Edition)",
        layout="wide",
    )

    # ---- Custom CSS ----
    st.markdown(
        """
        <style>
        /* ì „ì²´ í˜ì´ì§€ ì—¬ë°± ì¡°ê¸ˆ ì¤„ì´ê¸° */
        .block-container {
            padding-top: 1.5rem;
            padding-bottom: 3rem;
        }

        /* í—¤ë” ë°•ìŠ¤ */
        .main-header {
            background: linear-gradient(90deg, #003b8e, #2563eb);
            padding: 1.6rem 2.0rem;
            border-radius: 16px;
            color: white;
            margin-bottom: 1.8rem;
        }

        .main-header h1 {
            font-size: 1.8rem;
            margin-bottom: 0.3rem;
        }

        .main-header p {
            margin: 0;
            font-size: 0.95rem;
            opacity: 0.95;
        }

        /* ì—…ë¡œë“œ ì¹´ë“œ */
        .upload-card {
            background-color: #f3f6ff;
            border: 1px solid #c7d2ff;
            border-radius: 14px;
            padding: 1.4rem 1.6rem 1.6rem 1.6rem;
            margin-bottom: 1.2rem;
        }

        .upload-card h3 {
            margin-top: 0;
            margin-bottom: 0.4rem;
        }

        .upload-card p {
            margin-top: 0;
            font-size: 0.9rem;
            color: #4b5563;
        }

        /* êµì • ë‹¨ì–´ í•˜ì´ë¼ì´íŠ¸ */
        .corrected-word {
            background-color: #e0ecff;
            color: #003b8e;
            font-weight: 600;
            padding: 0 2px;
            border-radius: 3px;
        }

        .corrected-text-box {
            border-radius: 10px;
            border: 1px solid #e5e7eb;
            padding: 0.9rem 1.0rem;
            background-color: #ffffff;
            font-size: 0.95rem;
            line-height: 1.6;
            max-height: 350px;
            overflow-y: auto;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ---- í—¤ë” (ë¡œê³  + íƒ€ì´í‹€) ----
    st.markdown(
        """
        <div class="main-header">
          <div style="display:flex; align-items:center; gap:1.0rem;">
            <!-- ì—°ì„¸ëŒ€ ë¡œê³ : ê°™ì€ í´ë”ì— yonsei_logo.png íŒŒì¼ì„ ë„£ì–´ ë‘ì„¸ìš” -->
            <img src="yonsei_logo.png" alt="Yonsei Logo" width="46" style="border-radius: 8px; background-color:white; padding:4px;">
            <div>
              <h1>Blue Spell (Yonsei Edition)</h1>
              <p>ì˜ì–´ í…ìŠ¤íŠ¸ ì² ì êµì • ë° í†µê³„ ë¶„ì„ ë„êµ¬ Â· ì—¬ëŸ¬ ê°œì˜ .txt íŒŒì¼ì„ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤.</p>
            </div>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    ensure_nltk()
    spell = SpellChecker(language="en")

    # ---- Sidebar: ì˜µì…˜ ----
    with st.sidebar:
        st.header("ì˜µì…˜")

        min_len = st.number_input(
            "ì² ì í›„ë³´ë¡œ ë³¼ ìµœì†Œ ë‹¨ì–´ ê¸¸ì´",
            min_value=1,
            max_value=20,
            value=3,
        )
        ignore_all_caps = st.checkbox(
            "ëª¨ë‘ ëŒ€ë¬¸ì ë‹¨ì–´ ë¬´ì‹œ (ì˜ˆ: ABC)",
            value=True,
        )
        ignore_title = st.checkbox(
            "ì²« ê¸€ìë§Œ ëŒ€ë¬¸ìì¸ ë‹¨ì–´ ë¬´ì‹œ (ì˜ˆ: Yonsei)",
            value=True,
        )

        st.markdown("---")
        st.caption("ì»¤ìŠ¤í…€ ë¬´ì‹œ ë‹¨ì–´ ëª©ë¡ (.txt, í•œ ì¤„ë‹¹ í•œ ë‹¨ì–´)")
        custom_ignore_file = st.file_uploader(
            "ë¬´ì‹œí•  ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ì—…ë¡œë“œ",
            type=["txt"],
            key="ignore_list",
        )

    # ---- ë©”ì¸ ì˜ì—­: ì—…ë¡œë“œ ì¹´ë“œ ----
    st.markdown(
        """
        <div class="upload-card">
          <h3>1. ì² ì êµì •ì„ í•  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”</h3>
          <p>
            â€¢ <b>.txt</b> íŒŒì¼ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>
            â€¢ ê° íŒŒì¼ì˜ ë‚´ìš©ì— ëŒ€í•´ ì² ì ì˜¤ë¥˜ë¥¼ êµì •í•˜ê³ , êµì • í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
          </p>
        </div>
        """,
        unsafe_allow_html=True,
    )

    uploaded_files = st.file_uploader(
        "í…ìŠ¤íŠ¸ íŒŒì¼(.txt)ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ 'Browse files' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì„ íƒí•˜ì„¸ìš”.",
        type=["txt"],
        accept_multiple_files=True,
    )

    run_button = st.button("ğŸ” ì² ì ê²€ì‚¬ ì‹¤í–‰")

    if run_button:
        if not uploaded_files:
            st.warning("ë¨¼ì € í•˜ë‚˜ ì´ìƒì˜ .txt íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
            return

        # ì»¤ìŠ¤í…€ ignore ë¦¬ìŠ¤íŠ¸ ì½ê¸°
        custom_ignore = set()
        if custom_ignore_file is not None:
            try:
                content = custom_ignore_file.read().decode("utf-8", errors="ignore")
                custom_ignore = {
                    line.strip().lower()
                    for line in content.splitlines()
                    if line.strip()
                }
                st.sidebar.success(f"ë¬´ì‹œí•  ë‹¨ì–´ {len(custom_ignore)}ê°œ ë¡œë“œë¨")
            except Exception as e:
                st.sidebar.error(f"ë¬´ì‹œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        summary_rows = []

        st.markdown("### 2. êµì • ê²°ê³¼")

        for file in uploaded_files:
            try:
                raw = file.read().decode("utf-8", errors="ignore")
            except Exception:
                raw = file.read().decode("cp949", errors="ignore")

            corrected_text, highlighted_html, stats = run_spellcheck_on_text(
                raw,
                filename=file.name,
                spell_checker=spell,
                min_len=min_len,
                ignore_all_caps=ignore_all_caps,
                ignore_title=ignore_title,
                custom_ignore=custom_ignore,
            )

            st.subheader(f"ğŸ“„ íŒŒì¼: {file.name}")
            col1, col2, col3 = st.columns(3)
            col1.metric("ì „ì²´ í† í° ìˆ˜", stats["total_tokens"])
            col2.metric("ì² ì í›„ë³´ ë‹¨ì–´ ìˆ˜", stats["candidate_count"])
            col3.metric("ì‹¤ì œ êµì •ëœ ë‹¨ì–´ ìˆ˜", stats["corrected_count"])

            st.markdown("**êµì •ëœ í…ìŠ¤íŠ¸ (êµì •ëœ ë‹¨ì–´ëŠ” íŒŒë€ìƒ‰ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤)**")
            st.markdown(
                f'<div class="corrected-text-box">{highlighted_html}</div>',
                unsafe_allow_html=True,
            )

            st.download_button(
                label="ğŸ’¾ êµì •ëœ í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=corrected_text.encode("utf-8"),
                file_name=f"{file.name.rsplit('.', 1)[0]}_corrected.txt",
                mime="text/plain",
            )

            summary_rows.append(stats)

        if summary_rows:
            st.markdown("### 3. ì „ì²´ íŒŒì¼ ìš”ì•½ í†µê³„")
            df = pd.DataFrame(summary_rows)
            st.dataframe(df, use_container_width=True)

            csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ğŸ“Š ìš”ì•½ í†µê³„ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_bytes,
                file_name="spelling_summary.csv",
                mime="text/csv",
            )


if __name__ == "__main__":
    main()

